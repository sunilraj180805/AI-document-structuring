{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF path: C:\\Users\\Sunilraj\\Desktop\\Assignment_r\\solution\\Data_Input.pdf\n",
      "Output will be saved as: C:\\Users\\Sunilraj\\Desktop\\Assignment_r\\solution\\Output.xlsx\n"
     ]
    }
   ],
   "source": [
    "import PyPDF2\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# ---------- File paths ----------\n",
    "\n",
    "# Assuming your notebook, PDF, and output will all be in the same folder.\n",
    "BASE_DIR = Path(\".\")  # current folder\n",
    "\n",
    "PDF_PATH = BASE_DIR / \"Data_Input.pdf\"\n",
    "OUTPUT_EXCEL_PATH = BASE_DIR / \"Output.xlsx\"\n",
    "\n",
    "print(\"PDF path:\", PDF_PATH.resolve())\n",
    "print(\"Output will be saved as:\", OUTPUT_EXCEL_PATH.resolve())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages in PDF: 1\n",
      "First 500 characters of extracted text:\n",
      "\n",
      "Vijay Kumar was born on March 15, 1989, in Jaipur, Rajasthan, making him 35 years old as of 2024. \n",
      "His birthdate is formatted as 1989 -03-15 in ISO format for easy parsing, while his age serves as a \n",
      "key demographic marker for analytical purposes. Born and ra ised in the Pink City of India, his \n",
      "birthplace provides valuable regional profiling context, and his O+ blood group is noted for \n",
      "emergency contact purposes. As an Indian national, his citizenship status is important for \n",
      "understanding his\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(pdf_path: Path) -> str:\n",
    "    if not pdf_path.exists():\n",
    "        raise FileNotFoundError(f\"PDF file not found at: {pdf_path}\")\n",
    "\n",
    "    all_text = []\n",
    "\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        num_pages = len(reader.pages)\n",
    "        print(f\"Number of pages in PDF: {num_pages}\")\n",
    "\n",
    "        for i in range(num_pages):\n",
    "            page = reader.pages[i]\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                all_text.append(page_text.strip())\n",
    "            else:\n",
    "                print(f\"Warning: No text extracted from page {i}\")\n",
    "\n",
    "    # Join pages with two newlines between them\n",
    "    full_text = \"\\n\\n\".join(all_text)\n",
    "    return full_text\n",
    "\n",
    "\n",
    "# ---- Use the function and preview the first part of the text ----\n",
    "pdf_text = extract_text_from_pdf(PDF_PATH)\n",
    "\n",
    "print(\"First 500 characters of extracted text:\\n\")\n",
    "print(pdf_text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gemini API key loaded successfully.\n",
      "Using model: gemini-1.5-flash\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Read API key from environment variable\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if api_key is None:\n",
    "    raise ValueError(\"GOOGLE_API_KEY is not set in your environment variables.\")\n",
    "\n",
    "genai.configure(api_key=api_key)\n",
    "\n",
    "# Model name (Free + Powerful)\n",
    "GEMINI_MODEL_NAME = \"gemini-1.5-flash\"\n",
    "\n",
    "print(\"Gemini API key loaded successfully.\")\n",
    "print(\"Using model:\", GEMINI_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 57 models:\n",
      "\n",
      "Model #1\n",
      "  name        : models/embedding-gecko-001\n",
      "  displayName : Embedding Gecko\n",
      "  description : Obtain a distributed representation of a text.\n",
      "  supported_generation_methods: ['embedText', 'countTextTokens']\n",
      "------------------------------------------------------------\n",
      "Model #2\n",
      "  name        : models/gemini-2.5-flash\n",
      "  displayName : Gemini 2.5 Flash\n",
      "  description : Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #3\n",
      "  name        : models/gemini-2.5-pro\n",
      "  displayName : Gemini 2.5 Pro\n",
      "  description : Stable release (June 17th, 2025) of Gemini 2.5 Pro\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #4\n",
      "  name        : models/gemini-2.0-flash-exp\n",
      "  displayName : Gemini 2.0 Flash Experimental\n",
      "  description : Gemini 2.0 Flash Experimental\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #5\n",
      "  name        : models/gemini-2.0-flash\n",
      "  displayName : Gemini 2.0 Flash\n",
      "  description : Gemini 2.0 Flash\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #6\n",
      "  name        : models/gemini-2.0-flash-001\n",
      "  displayName : Gemini 2.0 Flash 001\n",
      "  description : Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #7\n",
      "  name        : models/gemini-2.0-flash-exp-image-generation\n",
      "  displayName : Gemini 2.0 Flash (Image Generation) Experimental\n",
      "  description : Gemini 2.0 Flash (Image Generation) Experimental\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'bidiGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #8\n",
      "  name        : models/gemini-2.0-flash-lite-001\n",
      "  displayName : Gemini 2.0 Flash-Lite 001\n",
      "  description : Stable version of Gemini 2.0 Flash-Lite\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #9\n",
      "  name        : models/gemini-2.0-flash-lite\n",
      "  displayName : Gemini 2.0 Flash-Lite\n",
      "  description : Gemini 2.0 Flash-Lite\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #10\n",
      "  name        : models/gemini-2.0-flash-lite-preview-02-05\n",
      "  displayName : Gemini 2.0 Flash-Lite Preview 02-05\n",
      "  description : Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #11\n",
      "  name        : models/gemini-2.0-flash-lite-preview\n",
      "  displayName : Gemini 2.0 Flash-Lite Preview\n",
      "  description : Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #12\n",
      "  name        : models/gemini-2.0-pro-exp\n",
      "  displayName : Gemini 2.0 Pro Experimental\n",
      "  description : Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #13\n",
      "  name        : models/gemini-2.0-pro-exp-02-05\n",
      "  displayName : Gemini 2.0 Pro Experimental 02-05\n",
      "  description : Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #14\n",
      "  name        : models/gemini-exp-1206\n",
      "  displayName : Gemini Experimental 1206\n",
      "  description : Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #15\n",
      "  name        : models/gemini-2.5-flash-preview-tts\n",
      "  displayName : Gemini 2.5 Flash Preview TTS\n",
      "  description : Gemini 2.5 Flash Preview TTS\n",
      "  supported_generation_methods: ['countTokens', 'generateContent']\n",
      "------------------------------------------------------------\n",
      "Model #16\n",
      "  name        : models/gemini-2.5-pro-preview-tts\n",
      "  displayName : Gemini 2.5 Pro Preview TTS\n",
      "  description : Gemini 2.5 Pro Preview TTS\n",
      "  supported_generation_methods: ['countTokens', 'generateContent']\n",
      "------------------------------------------------------------\n",
      "Model #17\n",
      "  name        : models/learnlm-2.0-flash-experimental\n",
      "  displayName : LearnLM 2.0 Flash Experimental\n",
      "  description : LearnLM 2.0 Flash Experimental\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #18\n",
      "  name        : models/gemma-3-1b-it\n",
      "  displayName : Gemma 3 1B\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #19\n",
      "  name        : models/gemma-3-4b-it\n",
      "  displayName : Gemma 3 4B\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #20\n",
      "  name        : models/gemma-3-12b-it\n",
      "  displayName : Gemma 3 12B\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #21\n",
      "  name        : models/gemma-3-27b-it\n",
      "  displayName : Gemma 3 27B\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #22\n",
      "  name        : models/gemma-3n-e4b-it\n",
      "  displayName : Gemma 3n E4B\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #23\n",
      "  name        : models/gemma-3n-e2b-it\n",
      "  displayName : Gemma 3n E2B\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #24\n",
      "  name        : models/gemini-flash-latest\n",
      "  displayName : Gemini Flash Latest\n",
      "  description : Latest release of Gemini Flash\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #25\n",
      "  name        : models/gemini-flash-lite-latest\n",
      "  displayName : Gemini Flash-Lite Latest\n",
      "  description : Latest release of Gemini Flash-Lite\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #26\n",
      "  name        : models/gemini-pro-latest\n",
      "  displayName : Gemini Pro Latest\n",
      "  description : Latest release of Gemini Pro\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #27\n",
      "  name        : models/gemini-2.5-flash-lite\n",
      "  displayName : Gemini 2.5 Flash-Lite\n",
      "  description : Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #28\n",
      "  name        : models/gemini-2.5-flash-image-preview\n",
      "  displayName : Nano Banana\n",
      "  description : Gemini 2.5 Flash Preview Image\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #29\n",
      "  name        : models/gemini-2.5-flash-image\n",
      "  displayName : Nano Banana\n",
      "  description : Gemini 2.5 Flash Preview Image\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #30\n",
      "  name        : models/gemini-2.5-flash-preview-09-2025\n",
      "  displayName : Gemini 2.5 Flash Preview Sep 2025\n",
      "  description : Gemini 2.5 Flash Preview Sep 2025\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #31\n",
      "  name        : models/gemini-2.5-flash-lite-preview-09-2025\n",
      "  displayName : Gemini 2.5 Flash-Lite Preview Sep 2025\n",
      "  description : Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #32\n",
      "  name        : models/gemini-3-pro-preview\n",
      "  displayName : Gemini 3 Pro Preview\n",
      "  description : Gemini 3 Pro Preview\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'createCachedContent', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #33\n",
      "  name        : models/gemini-3-pro-image-preview\n",
      "  displayName : Nano Banana Pro\n",
      "  description : Gemini 3 Pro Image Preview\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #34\n",
      "  name        : models/nano-banana-pro-preview\n",
      "  displayName : Nano Banana Pro\n",
      "  description : Gemini 3 Pro Image Preview\n",
      "  supported_generation_methods: ['generateContent', 'countTokens', 'batchGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #35\n",
      "  name        : models/gemini-robotics-er-1.5-preview\n",
      "  displayName : Gemini Robotics-ER 1.5 Preview\n",
      "  description : Gemini Robotics-ER 1.5 Preview\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #36\n",
      "  name        : models/gemini-2.5-computer-use-preview-10-2025\n",
      "  displayName : Gemini 2.5 Computer Use Preview 10-2025\n",
      "  description : Gemini 2.5 Computer Use Preview 10-2025\n",
      "  supported_generation_methods: ['generateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #37\n",
      "  name        : models/embedding-001\n",
      "  displayName : Embedding 001\n",
      "  description : Obtain a distributed representation of a text.\n",
      "  supported_generation_methods: ['embedContent']\n",
      "------------------------------------------------------------\n",
      "Model #38\n",
      "  name        : models/text-embedding-004\n",
      "  displayName : Text Embedding 004\n",
      "  description : Obtain a distributed representation of a text.\n",
      "  supported_generation_methods: ['embedContent']\n",
      "------------------------------------------------------------\n",
      "Model #39\n",
      "  name        : models/gemini-embedding-exp-03-07\n",
      "  displayName : Gemini Embedding Experimental 03-07\n",
      "  description : Obtain a distributed representation of a text.\n",
      "  supported_generation_methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #40\n",
      "  name        : models/gemini-embedding-exp\n",
      "  displayName : Gemini Embedding Experimental\n",
      "  description : Obtain a distributed representation of a text.\n",
      "  supported_generation_methods: ['embedContent', 'countTextTokens', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #41\n",
      "  name        : models/gemini-embedding-001\n",
      "  displayName : Gemini Embedding 001\n",
      "  description : Obtain a distributed representation of a text.\n",
      "  supported_generation_methods: ['embedContent', 'countTextTokens', 'countTokens', 'asyncBatchEmbedContent']\n",
      "------------------------------------------------------------\n",
      "Model #42\n",
      "  name        : models/aqa\n",
      "  displayName : Model that performs Attributed Question Answering.\n",
      "  description : Model trained to return answers to questions that are grounded in provided sources, along with estimating answerable probability.\n",
      "  supported_generation_methods: ['generateAnswer']\n",
      "------------------------------------------------------------\n",
      "Model #43\n",
      "  name        : models/imagen-4.0-generate-preview-06-06\n",
      "  displayName : Imagen 4 (Preview)\n",
      "  description : Vertex served Imagen 4.0 model\n",
      "  supported_generation_methods: ['predict']\n",
      "------------------------------------------------------------\n",
      "Model #44\n",
      "  name        : models/imagen-4.0-ultra-generate-preview-06-06\n",
      "  displayName : Imagen 4 Ultra (Preview)\n",
      "  description : Vertex served Imagen 4.0 ultra model\n",
      "  supported_generation_methods: ['predict']\n",
      "------------------------------------------------------------\n",
      "Model #45\n",
      "  name        : models/imagen-4.0-generate-001\n",
      "  displayName : Imagen 4\n",
      "  description : Vertex served Imagen 4.0 model\n",
      "  supported_generation_methods: ['predict']\n",
      "------------------------------------------------------------\n",
      "Model #46\n",
      "  name        : models/imagen-4.0-ultra-generate-001\n",
      "  displayName : Imagen 4 Ultra\n",
      "  description : Vertex served Imagen 4.0 ultra model\n",
      "  supported_generation_methods: ['predict']\n",
      "------------------------------------------------------------\n",
      "Model #47\n",
      "  name        : models/imagen-4.0-fast-generate-001\n",
      "  displayName : Imagen 4 Fast\n",
      "  description : Vertex served Imagen 4.0 Fast model\n",
      "  supported_generation_methods: ['predict']\n",
      "------------------------------------------------------------\n",
      "Model #48\n",
      "  name        : models/veo-2.0-generate-001\n",
      "  displayName : Veo 2\n",
      "  description : Vertex served Veo 2 model. Access to this model requires billing to be enabled on the associated Google Cloud Platform account. Please visit https://console.cloud.google.com/billin...\n",
      "  supported_generation_methods: ['predictLongRunning']\n",
      "------------------------------------------------------------\n",
      "Model #49\n",
      "  name        : models/veo-3.0-generate-001\n",
      "  displayName : Veo 3\n",
      "  description : Veo 3\n",
      "  supported_generation_methods: ['predictLongRunning']\n",
      "------------------------------------------------------------\n",
      "Model #50\n",
      "  name        : models/veo-3.0-fast-generate-001\n",
      "  displayName : Veo 3 fast\n",
      "  description : Veo 3 fast\n",
      "  supported_generation_methods: ['predictLongRunning']\n",
      "------------------------------------------------------------\n",
      "Model #51\n",
      "  name        : models/veo-3.1-generate-preview\n",
      "  displayName : Veo 3.1\n",
      "  description : Veo 3.1\n",
      "  supported_generation_methods: ['predictLongRunning']\n",
      "------------------------------------------------------------\n",
      "Model #52\n",
      "  name        : models/veo-3.1-fast-generate-preview\n",
      "  displayName : Veo 3.1 fast\n",
      "  description : Veo 3.1 fast\n",
      "  supported_generation_methods: ['predictLongRunning']\n",
      "------------------------------------------------------------\n",
      "Model #53\n",
      "  name        : models/gemini-2.0-flash-live-001\n",
      "  displayName : Gemini 2.0 Flash 001\n",
      "  description : Gemini 2.0 Flash 001\n",
      "  supported_generation_methods: ['bidiGenerateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #54\n",
      "  name        : models/gemini-live-2.5-flash-preview\n",
      "  displayName : Gemini Live 2.5 Flash Preview\n",
      "  description : Gemini Live 2.5 Flash Preview\n",
      "  supported_generation_methods: ['bidiGenerateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #55\n",
      "  name        : models/gemini-2.5-flash-live-preview\n",
      "  displayName : Gemini 2.5 Flash Live Preview\n",
      "  description : Gemini 2.5 Flash Live Preview\n",
      "  supported_generation_methods: ['bidiGenerateContent', 'countTokens']\n",
      "------------------------------------------------------------\n",
      "Model #56\n",
      "  name        : models/gemini-2.5-flash-native-audio-latest\n",
      "  displayName : Gemini 2.5 Flash Native Audio Latest\n",
      "  description : Latest release of Gemini 2.5 Flash Native Audio\n",
      "  supported_generation_methods: ['countTokens', 'bidiGenerateContent']\n",
      "------------------------------------------------------------\n",
      "Model #57\n",
      "  name        : models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "  displayName : Gemini 2.5 Flash Native Audio Preview 09-2025\n",
      "  description : Gemini 2.5 Flash Native Audio Preview 09-2025\n",
      "  supported_generation_methods: ['countTokens', 'bidiGenerateContent']\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "# list_models() returns a generator → convert to list\n",
    "models = list(genai.list_models())\n",
    "\n",
    "print(f\"Found {len(models)} models:\\n\")\n",
    "\n",
    "for i, m in enumerate(models, 1):\n",
    "    # model objects differ by SDK version, so we try common fields\n",
    "    name = getattr(m, \"name\", None) or getattr(m, \"model\", None) or getattr(m, \"id\", None)\n",
    "    display_name = getattr(m, \"displayName\", None) or getattr(m, \"display_name\", None)\n",
    "    description = getattr(m, \"description\", None)\n",
    "\n",
    "    print(f\"Model #{i}\")\n",
    "    print(\"  name        :\", name)\n",
    "    if display_name:\n",
    "        print(\"  displayName :\", display_name)\n",
    "    if description:\n",
    "        print(\"  description :\", (description[:180] + \"...\") if len(description) > 180 else description)\n",
    "\n",
    "    # Some SDK versions expose supported methods\n",
    "    if hasattr(m, \"supported_generation_methods\"):\n",
    "        print(\"  supported_generation_methods:\", m.supported_generation_methods)\n",
    "\n",
    "    print(\"-\" * 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted records (count): 62\n",
      "First 6 records preview:\n",
      "{'key': 'Name', 'value': 'Vijay Kumar', 'comments': \"Subject's full name as listed in the profile.\"}\n",
      "{'key': 'Date of Birth', 'value': 'March 15, 1989', 'comments': 'Exact date of birth provided in the document.'}\n",
      "{'key': 'Birth City', 'value': 'Jaipur', 'comments': 'City of birth provides valuable regional profiling context.'}\n",
      "{'key': 'Birth State', 'value': 'Rajasthan', 'comments': 'State of birth mentioned in the document.'}\n",
      "{'key': 'Current Age', 'value': '35 years old', 'comments': 'Age as of 2024 serves as a key demographic marker for analytical purposes.'}\n",
      "{'key': 'Age Reference Year', 'value': '2024', 'comments': 'The specific year for which the current age is referenced.'}\n"
     ]
    }
   ],
   "source": [
    "# Cell: Robust Gemini extraction that enforces meaningful, non-empty COMMENTS (with fallback single-record comment generation)\n",
    "# Paste & run this after you have configured genai (api key) and extracted pdf_text earlier.\n",
    "import json\n",
    "import google.generativeai as genai\n",
    "from typing import List, Dict\n",
    "\n",
    "# Choose model from your available list\n",
    "GEMINI_MODEL_NAME = \"models/gemini-2.5-flash\"\n",
    "\n",
    "def _normalize_single_record(rec) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Normalize a single record into keys: key, value, comments (strings).\n",
    "    Accept alternate key names and ensure strings.\n",
    "    \"\"\"\n",
    "    if isinstance(rec, str):\n",
    "        return {\"key\": \"Unlabeled Fact\", \"value\": rec.strip(), \"comments\": \"\"}\n",
    "\n",
    "    if not isinstance(rec, dict):\n",
    "        return {\"key\": \"Unlabeled Fact\", \"value\": str(rec), \"comments\": \"\"}\n",
    "\n",
    "    # map possible field names to canonical names\n",
    "    lower_map = {k.lower(): k for k in rec.keys()}\n",
    "    def find_field(candidates):\n",
    "        for c in candidates:\n",
    "            if c in lower_map:\n",
    "                return lower_map[c]\n",
    "        return None\n",
    "\n",
    "    key_field = find_field((\"key\", \"title\", \"label\", \"field\"))\n",
    "    value_field = find_field((\"value\", \"val\", \"text\", \"content\"))\n",
    "    comments_field = find_field((\"comments\", \"comment\", \"notes\", \"note\", \"context\", \"meta\"))\n",
    "\n",
    "    key = rec.get(key_field) if key_field else None\n",
    "    value = rec.get(value_field) if value_field else None\n",
    "    comments = rec.get(comments_field) if comments_field else \"\"\n",
    "\n",
    "    # if the model put a sentence in 'key' by mistake, shift it into value\n",
    "    if (value is None or value == \"\") and key is not None and isinstance(key, str) and len(key.split()) > 6:\n",
    "        value = key\n",
    "        key = \"Unlabeled Fact\"\n",
    "\n",
    "    # ensure value exists (try to pick any string field)\n",
    "    if value is None or value == \"\":\n",
    "        for k in rec:\n",
    "            if isinstance(rec[k], str) and rec[k].strip():\n",
    "                value = rec[k]\n",
    "                break\n",
    "    if value is None:\n",
    "        value = \"\"\n",
    "\n",
    "    if key is None or str(key).strip() == \"\":\n",
    "        short_key = \" \".join(value.strip().split()[:3]) or \"Unlabeled Fact\"\n",
    "        key = short_key if len(short_key) <= 40 else short_key[:40].strip()\n",
    "\n",
    "    return {\"key\": str(key).strip(), \"value\": str(value).strip(), \"comments\": str(comments).strip()}\n",
    "\n",
    "def _generate_single_comment_from_model(key: str, value: str, doc_text: str) -> str:\n",
    "    \"\"\"\n",
    "    If the model omitted a comments field, call the model to generate a single\n",
    "    concise, grounded comment for this (key, value) using only information present\n",
    "    in doc_text. If no contextual info is present, return a safe fallback string.\n",
    "    The returned text should be a short sentence (<= 30 words).\n",
    "    \"\"\"\n",
    "    prompt = (\n",
    "        \"You will be given a document (source) and a single extracted fact (key + value). \"\n",
    "        \"Produce exactly ONE concise sentence (comment) that explains the significance, \"\n",
    "        \"purpose, or context of the VALUE using ONLY information present in the SOURCE. \"\n",
    "        \"Do NOT invent or assume new facts. If the SOURCE contains no additional context \"\n",
    "        \"for this value, return exactly: No additional context available.\\n\\n\"\n",
    "        \"SOURCE:\\n\"\n",
    "        f\"\\\"\\\"\\\"{doc_text}\\\"\\\"\\\"\\n\\n\"\n",
    "        f\"FACT KEY: {key}\\n\"\n",
    "        f\"FACT VALUE: {value}\\n\\n\"\n",
    "        \"Output ONLY the single sentence comment (no JSON, no quotes).\"\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "        resp = model.generate_content(prompt)\n",
    "        raw = \"\"\n",
    "        if hasattr(resp, \"text\") and resp.text:\n",
    "            raw = resp.text.strip()\n",
    "        elif hasattr(resp, \"candidates\") and resp.candidates:\n",
    "            raw = resp.candidates[0].content.strip()\n",
    "        else:\n",
    "            raw = str(resp).strip()\n",
    "\n",
    "        # sometimes the model may return code fences or extra whitespace - clean it\n",
    "        if raw.startswith(\"```\"):\n",
    "            first = raw.find(\"```\")\n",
    "            last = raw.rfind(\"```\")\n",
    "            inner = raw[first+3:last].strip() if last > first else raw.strip(\"`\").strip()\n",
    "            raw = inner\n",
    "        # ensure single-line, single sentence fallback if model returns multiple lines\n",
    "        raw = raw.replace(\"\\n\", \" \").strip()\n",
    "        # final safety: if it looks like an instruction or too long, truncate politely\n",
    "        if len(raw.split()) > 50:\n",
    "            raw = \" \".join(raw.split()[:45]) + \"...\"\n",
    "        # if model returned empty, provide canonical fallback\n",
    "        if raw == \"\":\n",
    "            return \"No additional context available.\"\n",
    "        return raw\n",
    "    except Exception:\n",
    "        # On any error, return a safe fallback (keeps the pipeline moving)\n",
    "        return \"No additional context available.\"\n",
    "\n",
    "def call_llm_for_extraction_with_rich_comments(document_text: str) -> List[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Primary function to get atomic records with meaningful comments.\n",
    "    1) Ask Gemini to produce JSON array of objects {key,value,comments}.\n",
    "    2) Normalize each returned record to ensure canonical keys exist.\n",
    "    3) For any record with empty comments, call a tiny helper prompt to generate a grounded comment.\n",
    "    4) Return normalized list where every record has non-empty 'comments' (or safe fallback).\n",
    "    \"\"\"\n",
    "    # Detailed prompt that enforces meaningful comments and examples\n",
    "    system_instructions = (\n",
    "        \"You are an assistant that turns an unstructured document into a list of atomic facts. \"\n",
    "        \"Return ONLY valid JSON — a single JSON array. Each element must be an object with fields: \"\n",
    "        \"\\\"key\\\" (short label), \\\"value\\\" (original wording), \\\"comments\\\" (concise context/interpretation). \"\n",
    "        \"CRITICAL: Comments must be meaningful, non-empty, and derived from the document text. \"\n",
    "        \"Do NOT invent facts. Preserve original wording in 'value' and only paraphrase for 'key'.\"\n",
    "    )\n",
    "\n",
    "    # Provide explicit examples (few-shot) to show desired comment style\n",
    "    few_shot_examples = \"\"\"\n",
    "Example (illustrative):\n",
    "\n",
    "Source snippet:\n",
    "\"John Doe was born on January 2, 1990 in Mumbai. His birthdate is formatted as 1990-01-02 in ISO format.\"\n",
    "\n",
    "Desired JSON elements:\n",
    "[\n",
    "  {\n",
    "    \"key\": \"Name\",\n",
    "    \"value\": \"John Doe\",\n",
    "    \"comments\": \"Subject's full name as listed in the profile.\"\n",
    "  },\n",
    "  {\n",
    "    \"key\": \"Date of Birth\",\n",
    "    \"value\": \"January 2, 1990\",\n",
    "    \"comments\": \"Exact date of birth used for age verification.\"\n",
    "  },\n",
    "  {\n",
    "    \"key\": \"Birth Date (ISO)\",\n",
    "    \"value\": \"1990-01-02\",\n",
    "    \"comments\": \"ISO formatted date included for machine parsing.\"\n",
    "  },\n",
    "  {\n",
    "    \"key\": \"Birth Place\",\n",
    "    \"value\": \"Mumbai\",\n",
    "    \"comments\": \"City of birth useful for regional demographic profiling.\"\n",
    "  }\n",
    "]\n",
    "\"\"\"\n",
    "\n",
    "    user_instructions = f\"\"\"\n",
    "Here is the full document text to structure:\n",
    "\n",
    "\\\"\\\"\\\"{document_text}\\\"\\\"\\\"\n",
    "\n",
    "Return ONLY a JSON array with objects exactly like:\n",
    "[\n",
    "  {{\n",
    "    \"key\": \"...\",\n",
    "    \"value\": \"...\",\n",
    "    \"comments\": \"...\"\n",
    "  }},\n",
    "  ...\n",
    "]\n",
    "\n",
    "NOTES on COMMENTS:\n",
    "- Comments should be short (one sentence), descriptive, and explain the significance or context of the VALUE.\n",
    "- Do NOT repeat the VALUE itself.\n",
    "- Do NOT add facts not present in the source.\n",
    "- If the source provides no additional context for a value, include a short neutral comment like: \"No additional context available.\"\n",
    "- Keys should be concise (2-4 words). Values must preserve original wording (except trivial spacing fixes).\n",
    "\n",
    "Now output ONLY the JSON array. Do NOT include any extra text or explanation.\n",
    "\"\"\"\n",
    "\n",
    "    full_prompt = system_instructions + \"\\n\\n\" + few_shot_examples + \"\\n\\n\" + user_instructions\n",
    "\n",
    "    # call model\n",
    "    model = genai.GenerativeModel(GEMINI_MODEL_NAME)\n",
    "    resp = model.generate_content(full_prompt)\n",
    "\n",
    "    # Extract raw text robustly\n",
    "    raw_output = \"\"\n",
    "    if hasattr(resp, \"text\") and resp.text:\n",
    "        raw_output = resp.text\n",
    "    elif hasattr(resp, \"candidates\") and resp.candidates:\n",
    "        raw_output = resp.candidates[0].content\n",
    "    else:\n",
    "        raw_output = str(resp)\n",
    "    raw_output = raw_output.strip()\n",
    "\n",
    "    # strip triple-backtick fences if present\n",
    "    if raw_output.startswith(\"```\"):\n",
    "        first = raw_output.find(\"```\")\n",
    "        last = raw_output.rfind(\"```\")\n",
    "        inner = raw_output[first+3:last].strip() if last > first else raw_output.strip(\"`\").strip()\n",
    "        if inner.lower().startswith(\"json\"):\n",
    "            inner = inner[len(\"json\"):].strip()\n",
    "        raw_output = inner\n",
    "\n",
    "    # Try parse JSON\n",
    "    try:\n",
    "        parsed = json.loads(raw_output)\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Failed to parse JSON. Raw output (first 3000 chars):\\n\")\n",
    "        print(raw_output[:3000])\n",
    "        raise\n",
    "\n",
    "    # If parsed is a dict, try to find list inside; else wrap into list\n",
    "    if isinstance(parsed, dict):\n",
    "        found_list = None\n",
    "        for v in parsed.values():\n",
    "            if isinstance(v, list):\n",
    "                found_list = v\n",
    "                break\n",
    "        parsed = found_list or [parsed]\n",
    "\n",
    "    if not isinstance(parsed, list):\n",
    "        raise ValueError(\"Model output is not a JSON array as expected.\")\n",
    "\n",
    "    # Normalize entries (ensure key, value, comments exist)\n",
    "    normalized: List[Dict[str, str]] = []\n",
    "    for rec in parsed:\n",
    "        norm = _normalize_single_record(rec)\n",
    "        # If comments empty, attempt to generate one grounded in document_text\n",
    "        if norm.get(\"comments\", \"\").strip() == \"\":\n",
    "            generated_comment = _generate_single_comment_from_model(norm[\"key\"], norm[\"value\"], document_text)\n",
    "            norm[\"comments\"] = generated_comment\n",
    "        normalized.append(norm)\n",
    "\n",
    "    # Final check: ensure every record has non-empty comments (if still empty, put fallback)\n",
    "    for rec in normalized:\n",
    "        if not rec.get(\"comments\") or str(rec.get(\"comments\")).strip() == \"\":\n",
    "            rec[\"comments\"] = \"No additional context available.\"\n",
    "\n",
    "    return normalized\n",
    "\n",
    "# ---- Run the new function on your extracted PDF text (pdf_text must already exist) ----\n",
    "records_with_comments = call_llm_for_extraction_with_rich_comments(pdf_text)\n",
    "\n",
    "print(\"Extracted records (count):\", len(records_with_comments))\n",
    "print(\"First 6 records preview:\")\n",
    "for r in records_with_comments[:6]:\n",
    "    print(r)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned output with 62 rows to: C:\\Users\\Sunilraj\\Desktop\\Assignment_r\\solution\\Output.xlsx\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Value</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name</td>\n",
       "      <td>Vijay Kumar</td>\n",
       "      <td>Subject's full name as listed in the profile.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Date of Birth</td>\n",
       "      <td>March 15, 1989</td>\n",
       "      <td>Exact date of birth provided in the document.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Birth City</td>\n",
       "      <td>Jaipur</td>\n",
       "      <td>City of birth provides valuable regional profi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Birth State</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>State of birth mentioned in the document.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Current Age</td>\n",
       "      <td>35 years old</td>\n",
       "      <td>Age as of 2024 serves as a key demographic mar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Age Reference Year</td>\n",
       "      <td>2024</td>\n",
       "      <td>The specific year for which the current age is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Birth Date (ISO)</td>\n",
       "      <td>1989-03-15</td>\n",
       "      <td>ISO formatted birthdate included for easy pars...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Birthplace Context</td>\n",
       "      <td>Pink City of India</td>\n",
       "      <td>Descriptive nickname for his birthplace, Jaipur.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Blood Group</td>\n",
       "      <td>O+</td>\n",
       "      <td>Blood group noted for emergency contact purposes.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Citizenship Status</td>\n",
       "      <td>Indian national</td>\n",
       "      <td>Citizenship status is important for understand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>First Job Start Date</td>\n",
       "      <td>July 1, 2012</td>\n",
       "      <td>The start date of his professional journey at ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>First Job Role</td>\n",
       "      <td>Junior Developer</td>\n",
       "      <td>His initial role when he began his professiona...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Key               Value  \\\n",
       "0                   Name         Vijay Kumar   \n",
       "1          Date of Birth      March 15, 1989   \n",
       "2             Birth City              Jaipur   \n",
       "3            Birth State           Rajasthan   \n",
       "4            Current Age        35 years old   \n",
       "5     Age Reference Year                2024   \n",
       "6       Birth Date (ISO)          1989-03-15   \n",
       "7     Birthplace Context  Pink City of India   \n",
       "8            Blood Group                  O+   \n",
       "9     Citizenship Status     Indian national   \n",
       "10  First Job Start Date        July 1, 2012   \n",
       "11        First Job Role    Junior Developer   \n",
       "\n",
       "                                             Comments  \n",
       "0       Subject's full name as listed in the profile.  \n",
       "1       Exact date of birth provided in the document.  \n",
       "2   City of birth provides valuable regional profi...  \n",
       "3           State of birth mentioned in the document.  \n",
       "4   Age as of 2024 serves as a key demographic mar...  \n",
       "5   The specific year for which the current age is...  \n",
       "6   ISO formatted birthdate included for easy pars...  \n",
       "7    Descriptive nickname for his birthplace, Jaipur.  \n",
       "8   Blood group noted for emergency contact purposes.  \n",
       "9   Citizenship status is important for understand...  \n",
       "10  The start date of his professional journey at ...  \n",
       "11  His initial role when he began his professiona...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Cell A: normalize small formatting issues, convert to DataFrame, and save cleaned Excel\n",
    "import re\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def fix_iso_date_spacing(text: str) -> str:\n",
    "    \"\"\"Fix patterns like '1989 -03-15' or '1989- 03-15' -> '1989-03-15'.\"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return re.sub(r'(\\d{4})\\s*-\\s*(\\d{2})\\s*-\\s*(\\d{2})', r'\\1-\\2-\\3', text)\n",
    "\n",
    "# run normalization across all records\n",
    "normalized_records = []\n",
    "for rec in records_with_comments:  # from your previous cell\n",
    "    key = rec.get(\"key\",\"\").strip()\n",
    "    value = fix_iso_date_spacing(rec.get(\"value\",\"\").strip())\n",
    "    comments = fix_iso_date_spacing(rec.get(\"comments\",\"\").strip())\n",
    "    normalized_records.append({\"Key\": key, \"Value\": value, \"Comments\": comments})\n",
    "\n",
    "# Convert to DataFrame and replace any None/NaN with empty strings\n",
    "df_clean = pd.DataFrame(normalized_records, columns=[\"Key\",\"Value\",\"Comments\"]).fillna(\"\")\n",
    "\n",
    "# Optional: if you want to merge rows that are exact duplicates, uncomment:\n",
    "# df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Save cleaned file\n",
    "out_path = Path(\"Output.xlsx\")\n",
    "df_clean.to_excel(out_path, index=False)\n",
    "\n",
    "print(f\"Saved cleaned output with {len(df_clean)} rows to: {out_path.resolve()}\")\n",
    "display(df_clean.head(12))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
